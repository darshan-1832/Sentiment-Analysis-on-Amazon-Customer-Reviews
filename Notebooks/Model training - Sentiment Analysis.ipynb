{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "316240e8-c45c-434f-83cd-3f147bbd128c",
   "metadata": {},
   "source": [
    "Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bcb61754-aa19-4cce-8bdd-7e3bca2f6583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79391c4-73b6-4e43-a2c2-6a50c6cf1303",
   "metadata": {},
   "source": [
    "Read and pre-process the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ba1c61-134b-45a1-ae34-2ba217ad1f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/puvia/Darshan K M - PA2312052010003 - NLP - CT3/train2.csv',encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56916179-84e3-471a-8546-eebacb2e0e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Km²)</th>\n",
       "      <th>Density (P/Km²)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265</td>\n",
       "      <td>470.0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866272</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment Time of Tweet Age of User  \\\n",
       "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
       "1                             Sooo SAD  negative          noon       21-30   \n",
       "2                          bullying me  negative         night       31-45   \n",
       "3                       leave me alone  negative       morning       46-60   \n",
       "4                        Sons of ****,  negative          noon       60-70   \n",
       "\n",
       "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n",
       "0  Afghanistan          38928346         652860.0               60  \n",
       "1      Albania           2877797          27400.0              105  \n",
       "2      Algeria          43851044        2381740.0               18  \n",
       "3      Andorra             77265            470.0              164  \n",
       "4       Angola          32866272        1246700.0               26  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecedbdb4-84b3-4af2-afce-13bc8fe992c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].str.replace(r'http\\S+|www.\\S+','', regex=True)\n",
    "data['text'] = data['text'].str.replace(r'@\\w+','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95e2ead4-ad7a-45bd-a4ec-67eb16543558",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'positive': 2, 'neutral' : 0, 'negative': 1}\n",
    "data['sentiment'] = data['sentiment'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aef227bf-e8c4-4a00-9cc3-e6abdba38b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Km²)</th>\n",
       "      <th>Density (P/Km²)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>0</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>1</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>1</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>1</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265</td>\n",
       "      <td>470.0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>1</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866272</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text  sentiment Time of Tweet Age of User  \\\n",
       "0  I`d have responded, if I were going          0       morning        0-20   \n",
       "1                             Sooo SAD          1          noon       21-30   \n",
       "2                          bullying me          1         night       31-45   \n",
       "3                       leave me alone          1       morning       46-60   \n",
       "4                        Sons of ****,          1          noon       60-70   \n",
       "\n",
       "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n",
       "0  Afghanistan          38928346         652860.0               60  \n",
       "1      Albania           2877797          27400.0              105  \n",
       "2      Algeria          43851044        2381740.0               18  \n",
       "3      Andorra             77265            470.0              164  \n",
       "4       Angola          32866272        1246700.0               26  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e684e87-8c30-4a90-ad0c-72a0213d94e6",
   "metadata": {},
   "source": [
    "Split the data, initialize the BERT-Tokenizer and tokenize the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77121689-e4b8-4a29-b76e-3bffc3c06d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['selected_text'], data['sentiment'], test_size=0.2, random_state=42)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(list(map(str, X_train)), truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(list(map(str, X_test)), truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f272b0bb-7d13-4d66-b8f8-9731720e536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).batch(16)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1942bca8-08f8-4023-894d-5121da45f6fc",
   "metadata": {},
   "source": [
    "Initialize the model, loss calculation and optimizer and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b52f0ce-e227-4d0e-a4d9-2be623a16512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\puvia\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\puvia\\AppData\\Local\\Temp\\ipykernel_10724\\2723099429.py:2: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8d6629-12ce-4f4d-9a1f-f1a22df2ee87",
   "metadata": {},
   "source": [
    "Mention the number of epochs, validation data and fit the model to the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af2fe627-e5e9-4ab0-aaa0-cc880b4cf766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\puvia\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\puvia\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1551/1551 [==============================] - 3400s 2s/step - loss: 0.4127 - accuracy: 0.8414 - val_loss: 0.3359 - val_accuracy: 0.8722\n",
      "Epoch 2/3\n",
      "1551/1551 [==============================] - 3971s 3s/step - loss: 0.2570 - accuracy: 0.9062 - val_loss: 0.4077 - val_accuracy: 0.8604\n",
      "Epoch 3/3\n",
      "1551/1551 [==============================] - 3384s 2s/step - loss: 0.1527 - accuracy: 0.9487 - val_loss: 0.4757 - val_accuracy: 0.8599\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=3, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7420715c-13fe-496d-b1be-9eca4da86279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 [==============================] - 146s 367ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_dataset).logits\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "209dcd4f-884f-4b09-85c6-fb165a497628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.86      0.83      0.84      2549\n",
      "     neutral       0.88      0.86      0.87      1765\n",
      "    negative       0.84      0.91      0.87      1889\n",
      "\n",
      "    accuracy                           0.86      6203\n",
      "   macro avg       0.86      0.86      0.86      6203\n",
      "weighted avg       0.86      0.86      0.86      6203\n",
      "\n",
      "Accuracy: 0.8599064968563598\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=label_mapping.keys()))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e0e65a-31b3-4e2a-aab0-a9392110563a",
   "metadata": {},
   "source": [
    "**Inference:**\n",
    "\n",
    "The F1-scores for all classes are close (ranging from 0.84 to 0.87), indicating that the model performs consistently well across positive, neutral, and negative sentiments.\n",
    "\n",
    "The model excels in identifying negative sentiments (high recall of 0.91).\n",
    "Strong overall performance in precision, recall, and F1-scores across all classes.\n",
    "Improvement Areas:\n",
    "\n",
    "The positive class has slightly lower recall (0.83), meaning some actual positive samples are being misclassified.\n",
    "Further optimization may enhance precision and recall for the positive and neutral classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c43557-9001-47c9-a83b-9e2b69a0f888",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12879d17-dc3f-4875-a5cb-3c386cf9ae5a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0c2dcf-ea4c-43fa-a75c-6bc5d7782d23",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6233799-c1a1-4373-855a-50d21f1da9a8",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcac7577-7264-4e9c-8f99-abd386d353c9",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c79c7b-431b-4490-a010-b1cecf109dd6",
   "metadata": {},
   "source": [
    "**----------------------------------------------------------------------------------SENTIMENT ANALYSIS----------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dec69b7-41c9-47d3-9601-d4b264ade1e5",
   "metadata": {},
   "source": [
    "Funciton to Pre-process the input data and map the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ffc4dfd-cca2-4a0d-97a5-90f7b2e35c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "          \n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"tf\", truncation=True, padding=True, max_length=128)\n",
    "    \n",
    "    # Pass inputs through the model and get only logits\n",
    "    outputs = model(inputs).logits\n",
    "    \n",
    "    # Get the prediction by finding the index of the max logit\n",
    "    prediction = tf.argmax(outputs, axis=1).numpy()\n",
    "    \n",
    "    # Map the prediction to the sentiment label\n",
    "    sentiments = [k for pred in prediction for k, v in label_mapping.items() if v == pred]\n",
    "    return sentiments if len(sentiments) > 1 else sentiments[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec8fd2a-cdfb-419f-a2a8-76a16ee1fd5a",
   "metadata": {},
   "source": [
    "Load the data scraped from Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "65efb697-0995-43da-8ec0-0e079193511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the reviews data from a CSV file\n",
    "df = pd.read_csv(r\"C:\\Users\\puvia\\Darshan K M - PA2312052010003 - NLP - CT3\\amazon_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba81089b-e295-49af-a2a9-55f0efa534b9",
   "metadata": {},
   "source": [
    "Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0ab9019-052d-455b-8213-d491c12873d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all reviews to strings before processing\n",
    "reviews = df['Review'].astype(str).tolist()  # Convert to list of strings\n",
    "\n",
    "# Example: Get predictions for all reviews\n",
    "predicted_sentiments = [predict_sentiment(review) for review in reviews]\n",
    "\n",
    "# Add predictions back to the DataFrame\n",
    "df['Sentiment'] = predicted_sentiments\n",
    "\n",
    "df.to_csv('updated_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96e16146-8c66-4df5-b791-e09bde0d80b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group A Engagement Metrics: {'Average_Rating': 3.98, 'Review_Count': 50, 'Positive_Reviews': 31, 'Negative_Reviews': 2, 'Neutral_Reviews': 17}\n",
      "Group B Engagement Metrics: {'Average_Rating': 4.0, 'Review_Count': 50, 'Positive_Reviews': 24, 'Negative_Reviews': 3, 'Neutral_Reviews': 23}\n",
      "T-statistic: -0.37470140930053286, P-value: 0.7086921656430278\n",
      "There is no significant difference between the engagement of Group A and Group B.\n"
     ]
    }
   ],
   "source": [
    "# Perform A/B testing based on sentiment\n",
    "df['Group'] = np.where(df.index % 2 == 0, 'A', 'B')  # Randomly split users into A and B\n",
    "\n",
    "# Function to calculate engagement metrics\n",
    "def calculate_engagement(df):\n",
    "    engagement_metrics = {\n",
    "        'Average_Rating': df['Rating'].mean(),\n",
    "        'Review_Count': len(df),\n",
    "        'Positive_Reviews': (df['Sentiment'] == 'positive').sum(),\n",
    "        'Negative_Reviews': (df['Sentiment'] == 'negative').sum(),\n",
    "        'Neutral_Reviews': (df['Sentiment'] == 'neutral').sum()\n",
    "    }\n",
    "    return engagement_metrics\n",
    "\n",
    "# Calculate engagement metrics for both groups\n",
    "group_a_metrics = calculate_engagement(df[df['Group'] == 'A'])\n",
    "group_b_metrics = calculate_engagement(df[df['Group'] == 'B'])\n",
    "\n",
    "# Print engagement metrics\n",
    "print(\"Group A Engagement Metrics:\", group_a_metrics)\n",
    "print(\"Group B Engagement Metrics:\", group_b_metrics)\n",
    "\n",
    "# Perform statistical tests (e.g., T-test) to compare engagement metrics\n",
    "\n",
    "\n",
    "# Compare average ratings between Group A and Group B\n",
    "t_stat, p_value = stats.ttest_ind(df[df['Group'] == 'A']['Rating'], df[df['Group'] == 'B']['Rating'])\n",
    "\n",
    "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference between the engagement of Group A and Group B.\")\n",
    "else:\n",
    "    print(\"There is no significant difference between the engagement of Group A and Group B.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
